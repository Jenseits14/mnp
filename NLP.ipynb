{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####@author:gargla\n",
    "\n",
    "from bs4 import BeautifulSoup  \n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def cleanup_text(text):\n",
    "    step1Cleaned = BeautifulSoup(text,\"lxml\")\n",
    "    import re\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\",           # The pattern to search for\n",
    "                      \" \",                   # The pattern to replace it with\n",
    "                      step1Cleaned.get_text() )  # The text to search\n",
    "    lower_case = letters_only.lower()        \n",
    "    words = lower_case.split()\n",
    "    words = [w for w in words if not w in stopwords.words(\"english\")]\n",
    "    return words\n",
    "\n",
    "##get LIWC features for given word tokens\n",
    "def get_LIWC_features(words,categories):\n",
    "    feature_vector={}\n",
    "    for key,val in categories.items(): \n",
    "        itemcounter = {item:count for item, count in [(item, words.count(item)) for item in set(val)]}\n",
    "        feature_vector[key]=sum(itemcounter.values())\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "##read category files   \n",
    "def read_LIWC_categories():\n",
    "    ##TODO:move path to func param\n",
    "    path=\"english_dictionary\"\n",
    "    csvs = [f for f in listdir(path) if f.endswith('.csv')]\n",
    "    categories={}\n",
    "    for csv in csvs:\n",
    "        CatList=[]\n",
    "        with open(path+\"/\"+csv, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                l= line.strip().split(',')\n",
    "                CatList.extend(l)\n",
    "        categories[csv]=CatList\n",
    "    return categories\n",
    "\n",
    "def get_data_feature_vector(ResponseDataset):\n",
    "    columns = ResponseDataset.columns.values\n",
    "    categories = read_LIWC_categories()\n",
    "    #print columns\n",
    "    count = 0\n",
    "    feature_vector = {}\n",
    "    column_ignore_list=[\"id\",\"batch\"]\n",
    "    ##TODO:add exception handling insted\n",
    "    user_ignore_list=[\"usmt12\",\"usmt34\",\"nan\",\"usmt37\",\"ukbr1\",\n",
    "                      \"ukbr7\",\"ukbr25\",\"ukbr41\",\"ukbr73\",\"us12\",\"us15\",\n",
    "                      \"us39\",\"p3\",\"p9\",\"p18\",\"p35\",\"p41\",\"p46\",\"p53\",\"p62\",\n",
    "                      \"p69\",\"p72\",\"p76\",\"p91\",\"j6\",\"j9\",\"j10\",\"j17\",\"j25\",\n",
    "                      \"j26\",\"j30\",\"j36\",\"j42\",\"j43\",\"j45\",\"j75\",\"j90\",\"j111\",\n",
    "                     \"j113\",\"j115\",\"j117\",\"j118\",\"j120\",\"j124\",\"j126\",\"j127\",\"j128\",\"j130\"]\n",
    "    for row in range(ResponseDataset.shape[0]):\n",
    "    #iterate over each row to get categories for every user response and followups\n",
    "        userfeatureDict = {}\n",
    "        user = str(ResponseDataset[\"id\"][row])\n",
    "        if user in user_ignore_list:\n",
    "            continue\n",
    "        print \"getting features for id:\",user\n",
    "        for column in columns.tolist():\n",
    "            if column in column_ignore_list:\n",
    "                continue\n",
    "            text = ResponseDataset[column][row]\n",
    "            words = cleanup_text(text)\n",
    "            #print words\n",
    "            features = get_LIWC_features(words,categories)\n",
    "            #print column,\":\",features\n",
    "            userfeatureDict[str(column)]=features\n",
    "        feature_vector[user] = userfeatureDict\n",
    "    return feature_vector\n",
    "\n",
    "#pd.DataFrame(featureDict.items(), columns=[\"text\",\"featurecount\"])\n",
    "    \n",
    "def create_feature_df(feature_matrix):\n",
    "    user_ids = []\n",
    "    frames = []\n",
    "    for user_id, d in feature_matrix.iteritems():\n",
    "        user_ids.append(user_id)\n",
    "        frames.append(pd.DataFrame.from_dict(d, orient='index'))\n",
    "    \n",
    "    feature_df = pd.concat(frames, keys=user_ids)\n",
    "    return feature_df\n",
    "\n",
    "def processResponses(responsesFilePath):\n",
    "    ResponseDf = pd.ExcelFile(responsesFilePath)\n",
    "    ResponseDataset = ResponseDf.parse(0)\n",
    "    feature_vector = get_data_feature_vector(ResponseDataset)\n",
    "    feature_vector_df = create_feature_df(feature_vector)\n",
    "    return feature_vector_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encodeBinary(x, threshold=5):\n",
    "    \n",
    "    \"\"\"\n",
    "    encodes value into a binary variable i.e. if value > threshold: return 1, else return 0\n",
    "    Using this function to encode the entire Personality Dataframe\n",
    "    \n",
    "    Arguments: value, threshold(optional)<default=5>\n",
    "    \n",
    "    Output: binary value- 0 or 1\n",
    "    \n",
    "    \"\"\"\n",
    "    if(x>threshold):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encodeDF(personalityFilePath):\n",
    "    \"\"\"\n",
    "    encodes the personality score data into binary labels.  \n",
    "    \n",
    "    Arguments: path for the Personality Score csv file\n",
    "    \n",
    "    Output: Data frame with binary labels against each big 5 personality trait for each user\n",
    "    \n",
    "    \"\"\"\n",
    "    persData=pd.read_csv(personalityFilePath, header=0)\n",
    "    persData=persData.iloc[:,[0, 131,132,133,134,135]]\n",
    "    persData=persData[persData.Openness!=\"#NULL!\"] #Removing rows with no Personality form responses\n",
    "    persData[persData.columns[1:]]=persData[persData.columns[1:]].apply(pd.to_numeric)\n",
    "    for i in persData.columns[1:]:\n",
    "        persData[i]=persData[i].map(encodeBinary)\n",
    "    return persData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "responsesFilePath=\"data-qualitative responses across cultures_fordan.xlsx\"\n",
    "personalityFilePath=\"persData.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting features for id: usmt1\n",
      "getting features for id: usmt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ADI/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:24: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting features for id: usmt3\n",
      "getting features for id: usmt4\n",
      "getting features for id: usmt5\n",
      "getting features for id: usmt6\n",
      "getting features for id: usmt7\n",
      "getting features for id: usmt8\n",
      "getting features for id: usmt9\n",
      "getting features for id: usmt10\n",
      "getting features for id: usmt11\n",
      "getting features for id: usmt23\n",
      "getting features for id: usmt24\n",
      "getting features for id: usmt25\n",
      "getting features for id: usmt28\n",
      "getting features for id: usmt29\n",
      "getting features for id: usmt30\n",
      "getting features for id: usmt31\n",
      "getting features for id: usmt32\n",
      "getting features for id: usmt33\n",
      "getting features for id: usmt35\n",
      "getting features for id: usmt36\n",
      "getting features for id: usmt38\n",
      "getting features for id: usmt39\n",
      "getting features for id: usmt40\n",
      "getting features for id: usmt41\n",
      "getting features for id: usmt42\n",
      "getting features for id: usmt50\n",
      "getting features for id: usmt51\n",
      "getting features for id: usmt52\n",
      "getting features for id: usmt53\n",
      "getting features for id: usmt54\n",
      "getting features for id: indiap1\n",
      "getting features for id: indiap2\n",
      "getting features for id: indiap3\n",
      "getting features for id: indiap4\n",
      "getting features for id: indiap5\n",
      "getting features for id: kenya1\n",
      "getting features for id: southafrica1\n",
      "getting features for id: uk1\n",
      "getting features for id: uk3\n",
      "getting features for id: uk7\n",
      "getting features for id: uk8\n",
      "getting features for id: ukb3\n",
      "getting features for id: ukb4\n",
      "getting features for id: ukb5\n",
      "getting features for id: ukb6\n",
      "getting features for id: ukb8\n",
      "getting features for id: ukb9\n",
      "getting features for id: ukb10\n",
      "getting features for id: ukb11\n",
      "getting features for id: ukb12\n",
      "getting features for id: ukb13\n",
      "getting features for id: ukb14\n",
      "getting features for id: ukb15\n",
      "getting features for id: ukb16\n",
      "getting features for id: ukb17\n",
      "getting features for id: ukb18\n",
      "getting features for id: ukb19\n",
      "getting features for id: ukb20\n",
      "getting features for id: ukb21\n",
      "getting features for id: ukb22\n",
      "getting features for id: ukb29\n",
      "getting features for id: ukb30\n",
      "getting features for id: ukb31\n",
      "getting features for id: ukb32\n",
      "getting features for id: ukb69\n",
      "getting features for id: ukb80\n",
      "getting features for id: ukbr2\n",
      "getting features for id: ukbr3\n",
      "getting features for id: ukbr4\n",
      "getting features for id: ukbr5\n",
      "getting features for id: ukbr6\n",
      "getting features for id: ukbr33\n",
      "getting features for id: ukbr35\n",
      "getting features for id: ukbr36\n",
      "getting features for id: ukbr37\n",
      "getting features for id: ukbr38\n",
      "getting features for id: ukbr39\n",
      "getting features for id: ukbr40\n",
      "getting features for id: ukbr42\n",
      "getting features for id: ukbr43\n",
      "getting features for id: ukbr44\n",
      "getting features for id: ukbr45\n",
      "getting features for id: ukbr46\n",
      "getting features for id: ukbr60\n",
      "getting features for id: ukbr70\n",
      "getting features for id: ukbr71\n",
      "getting features for id: ukbr72\n",
      "getting features for id: ukbr74\n",
      "getting features for id: us1\n",
      "getting features for id: us2\n",
      "getting features for id: us3\n",
      "getting features for id: us4\n",
      "getting features for id: us5\n",
      "getting features for id: us9\n",
      "getting features for id: us14\n",
      "getting features for id: us16\n",
      "getting features for id: us17\n",
      "getting features for id: us18\n",
      "getting features for id: us21\n",
      "getting features for id: us22\n",
      "getting features for id: us23\n",
      "getting features for id: us24\n",
      "getting features for id: us25\n",
      "getting features for id: us26\n",
      "getting features for id: us28\n",
      "getting features for id: us44\n",
      "getting features for id: p4\n",
      "getting features for id: p5\n",
      "getting features for id: p6\n",
      "getting features for id: p7\n",
      "getting features for id: p8\n",
      "getting features for id: p36\n",
      "getting features for id: p37\n",
      "getting features for id: p38\n",
      "getting features for id: p39\n",
      "getting features for id: p40\n",
      "getting features for id: p42\n",
      "getting features for id: p45\n",
      "getting features for id: p47\n",
      "getting features for id: p48\n",
      "getting features for id: p49\n",
      "getting features for id: p50\n",
      "getting features for id: p51\n",
      "getting features for id: p52\n",
      "getting features for id: p54\n",
      "getting features for id: p55\n",
      "getting features for id: p56\n",
      "getting features for id: p57\n",
      "getting features for id: p58\n",
      "getting features for id: p59\n",
      "getting features for id: p60\n",
      "getting features for id: p61\n",
      "getting features for id: p63\n",
      "getting features for id: p64\n",
      "getting features for id: p65\n",
      "getting features for id: p68\n",
      "getting features for id: p70\n",
      "getting features for id: p71\n",
      "getting features for id: p73\n",
      "getting features for id: p74\n",
      "getting features for id: p75\n",
      "getting features for id: p78\n",
      "getting features for id: p79\n",
      "getting features for id: p80\n",
      "getting features for id: p81\n",
      "getting features for id: p88\n",
      "getting features for id: p97\n",
      "getting features for id: p98\n",
      "getting features for id: p112\n",
      "getting features for id: p113\n",
      "getting features for id: p115\n",
      "getting features for id: p119\n",
      "getting features for id: j2\n",
      "getting features for id: j8\n",
      "getting features for id: j11\n",
      "getting features for id: j12\n",
      "getting features for id: j13\n",
      "getting features for id: j14\n",
      "getting features for id: j15\n",
      "getting features for id: j16\n",
      "getting features for id: j18\n",
      "getting features for id: j19\n",
      "getting features for id: j20\n",
      "getting features for id: j21\n",
      "getting features for id: j22\n",
      "getting features for id: j23\n",
      "getting features for id: j24\n",
      "getting features for id: j27\n",
      "getting features for id: j28\n",
      "getting features for id: j29\n",
      "getting features for id: j31\n",
      "getting features for id: j32\n",
      "getting features for id: j33\n",
      "getting features for id: j34\n",
      "getting features for id: j35\n",
      "getting features for id: j37\n",
      "getting features for id: j38\n",
      "getting features for id: j39\n",
      "getting features for id: j41\n",
      "getting features for id: j44\n",
      "getting features for id: j46\n",
      "getting features for id: j47\n",
      "getting features for id: j48\n",
      "getting features for id: j49\n",
      "getting features for id: j50\n",
      "getting features for id: j51\n",
      "getting features for id: j62\n",
      "getting features for id: j77\n",
      "getting features for id: j82\n",
      "getting features for id: j87\n",
      "getting features for id: j92\n",
      "getting features for id: j96\n",
      "getting features for id: j98\n",
      "getting features for id: j101\n",
      "getting features for id: j107\n",
      "getting features for id: j108\n"
     ]
    }
   ],
   "source": [
    "liwcData=processResponses(responsesFilePath)\n",
    "persData=encodeDF(personalityFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id  Openness  Extraversion  Agreeableness  Conscientiousness  \\\n",
      "0  c10         1             1              0                  0   \n",
      "1  c11         1             1              0                  1   \n",
      "2  c12         1             0              0                  1   \n",
      "3  c13         1             0              1                  1   \n",
      "4  c14         1             0              0                  0   \n",
      "5  c15         1             0              0                  0   \n",
      "6  c16         1             1              0                  0   \n",
      "7   c2         1             1              0                  0   \n",
      "8   c3         1             0              0                  0   \n",
      "9   c4         1             1              0                  1   \n",
      "\n",
      "   EmotionalStability  \n",
      "0                   1  \n",
      "1                   0  \n",
      "2                   0  \n",
      "3                   1  \n",
      "4                   0  \n",
      "5                   0  \n",
      "6                   0  \n",
      "7                   0  \n",
      "8                   1  \n",
      "9                   0  \n",
      "Empty DataFrame\n",
      "Columns: [31.csv, 41.csv, 10.csv, 2.csv, 34.csv, 26.csv, 23.csv, 57.csv, 73.csv, 79.csv, 12.csv, 65.csv, 30.csv, 66.csv, 19.csv, 9.csv, 47.csv, 35.csv, 5.csv, 1.csv, 56.csv, 58.csv, 42.csv, 64.csv, 54.csv, 17.csv, 77.csv, 29.csv, 4.csv, 13.csv, 28.csv, 7.csv, 15.csv, 33.csv, 80.csv, 78.csv, 59.csv, 61.csv, 68.csv, 11.csv, 36.csv, 62.csv, 67.csv, 14.csv, 74.csv, 44.csv, 52.csv, 25.csv, 45.csv, 39.csv, 16.csv, 50.csv, 27.csv, 72.csv, 3.csv, 8.csv, 71.csv, 18.csv, 22.csv, 69.csv, 32.csv, 40.csv, 21.csv, 55.csv, 38.csv, 48.csv, 20.csv, 60.csv, 49.csv, 24.csv, 37.csv, 46.csv, 63.csv, 53.csv, 76.csv, 6.csv, 43.csv, 75.csv, 70.csv, 51.csv]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "print persData.head(10)\n",
    "print liwcData.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e1f41008053f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Merging LIWC and Personality data to create final dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfinalData\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliwcData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpersData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ADI/anaconda/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[1;32m     36\u001b[0m                          \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                          copy=copy, indicator=indicator)\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ADI/anaconda/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[1;32m    208\u001b[0m         (self.left_join_keys,\n\u001b[1;32m    209\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m          self.join_names) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ADI/anaconda/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                         \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m                     \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m                     \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0m_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_on\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ADI/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ADI/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2004\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ADI/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ADI/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3290\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3291\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ADI/anaconda/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1945\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "# Merging LIWC and Personality data to create final dataset\n",
    "\n",
    "finalData=pd.merge(liwcData,persData, left_on='id', right_on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print finalData.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
